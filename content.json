[{"title":"hexo 博客trip","date":"2017-05-17T07:31:11.000Z","path":"2017/05/17/hexo-博客trip/","text":"使用 toc添加 toc.ejs 在主题目录下新建toc.ejs, 增加一下内容 12345&lt;% if (post.toc != false) &#123; %&gt;&lt;div id=\"toc\"&gt; &lt;%- toc(post.content, &#123;list_number: false&#125;) %&gt;&lt;/div&gt;&lt;% &#125; %&gt; 这里的toc()函数就是Hexo官方提供的辅助函数，不用再自行写这部分代码了，直接调用toc()函数即可，post.content代表该文章内容，list_number: false是函数提供的一个配置参数，这里指定false代表文章列表不默认显示序号。 同时这段代码添加了一个文章变量toc，当在文章front-matter里添加toc: false时，就表示该文章不想显示目录。这样便可以控制哪些文章显示目录，哪些文章不想显示目录。 添加到页面中文章目录应该显示在文章内容的页面，这里将它放到文章的开始部分，找到主题目录文章布局文件layout/_partial/article.ejs，找到下面代码： 12345678910111213&lt;div class=\"article-entry\" itemprop=\"articleBody\"&gt; &lt;% if (post.excerpt &amp;&amp; index)&#123; %&gt; &lt;%- post.excerpt %&gt; &lt;% if (theme.excerpt_link)&#123; %&gt; &lt;p class=\"article-more-link\"&gt; &lt;a href=\"&lt;%- url_for(post.path) %&gt;#more\"&gt;&lt;%= theme.excerpt_link %&gt;&lt;/a&gt; &lt;/p&gt; &lt;% &#125; %&gt; &lt;% &#125; else &#123; %&gt; &lt;%- partial('toc') %&gt; &lt;%- post.content %&gt; &lt;% &#125; %&gt; &lt;/div&gt; 可以看到，在&lt;%- post.content %&gt;前面添加了一行&lt;%- partial(&#39;toc&#39;) %&gt;引用了目录代码。现在刷新页面就可以看到目录了. 修改目录样式上面也基本能满足文章目录的功能，只是不太好看，下面添加一些样式代码，让它看起来更美观一点。 在主题目录下source/css/_partial文件夹下找到article.styl文件，打开文件，在文件末端添加下面一段代码。 123456789...#toc float right background-color #eee font-size 0.8em color color-link margin 5px .toc list-style none 刷新页面即可。 more1&lt;!--more--&gt;","tags":[{"name":"hexo","slug":"hexo","permalink":"http://yoursite.com/tags/hexo/"}]},{"title":"集成学习","date":"2017-05-17T07:06:12.000Z","path":"2017/05/17/集成学习/","text":"概述本文是《机器学习》（周志华）的学习总结 boost","tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/tags/机器学习/"}]},{"title":"入职记","date":"2017-04-05T10:02:14.000Z","path":"2017/04/05/入职记/","text":"2017年4月5号，我正式入职了，彻底告别了学生生涯，进入了期待已久的职场生涯。虽然说期待已久，但是真的要离开学生时代内心是非常的不舍的，甚是可以说是有点忧伤。不过一切终究是要过去的，经历了毕设答辩的不顺利，公司实习的压力困难，找房子的琐碎分身（至今仍然蜗居宿舍）这段时间自己其实是有点自卑退缩的，经常感觉自己是个“水货”。更关键的是，自己一只特别希望能够在4月1号前入职，但是最终差了几天也没有实现，其实这对自己的打击还是很严重的。不过好在人生这么长，这点小事情从长远来看，真的也就不算什么了。 当然没能及时入职影响了我整个晋升的安排，所以如果年终既不能晋升也拿不到户口的话，18年我就会考虑和准备跳槽了，目标就是谷歌。当然晋升和户口也不是随随便便就能来的，也是靠自己最终拼来的。其实入职第一年，不需要考虑其他太多，好好积累，多学习，多向别人学习是第一重要的。 当然，我还有一个稍微大点的目标，那就是”谷歌+健身“。谷歌是自己的理想追求，健身是自己的审美需要。实现的方法也是自己之前总结的两点”自律+自信“ 浪费什么都不要浪费时间。说真的，时间真的是最宝贵的东西，浪费什么都不要浪费时间。陪家人的时间，努力学习的时间，运动的时间，休息的时间，真的都太重要了。和时间相比，眼前的一点小利真的都不算什么。多花点钱来打造自己良好的形象也是非常重要的。 最后是几个小习惯：早睡，多交流，日程记录，周报，周博客。 最后提醒自己：你已经正式入职了，已经不是学生了，请professional","tags":[{"name":"职场","slug":"职场","permalink":"http://yoursite.com/tags/职场/"}]},{"title":"c++","date":"2017-03-10T07:28:55.000Z","path":"2017/03/10/c/","text":"","tags":[]},{"title":"关于酒文化","date":"2017-01-29T08:28:48.000Z","path":"2017/01/29/关于酒文化/","text":"","tags":[]},{"title":"schedue for 2017","date":"2017-01-02T01:12:34.000Z","path":"2017/01/02/schedue-for-2017/","text":"本来2017年的第一天就该写这个计划的，结果以论文的借口给推辞了，今天想来一年计划是指导一年的行动的指南，这么重要的东西没理由推脱，所以一大早（其实很晚了）就准备攒这篇新年计划啦。今年的计划我想从主义，目标，习惯三个方面写写。 个人主义和极简主义极简主义从上一年开始就是自己所坚持的主义，回顾起来不是很满意。在生活物品的整理，减少非必需品的摄入，敢于舍弃等方面还是有点效果。但是极简主义的精髓部分还是没有完全掌握，最典型的就是为各种小事分散注意力。比如深夜抢红包，各种蝇头小利等等。我觉着原因是自己不知轻重，不知道什么才是最重要的事情，对于再面临这种情况的时候，你要告诉自己，时间才是最终的东西，这些浪费的时间本来可以创造更大的价值，即便有这些价值有可能不会被立即看到。所以，记住，下次再有这种事情发生的时候，去看书或者运动，效果应该非常好。说到看书，我就想到了今年经常发生的买书情景，因为价格一再推脱，浪费时间精力，甚至影响一整天的工作学习！对于这点，我还劝解自己的就是：要习惯于给优秀的内容和产品付费！ 个人主义，是今年读了《巨婴国》之后新总结出来的，还包括《爱是一种选择》。目前都还没有看完，先写下几句让我影响最深的话。“心理上弑母是男人走向独立成熟的必经步骤”，“剧做烂好人，保持攻击性” 目标 顺利毕业，争取3月份入职 连续两次3* +，顺利晋升。 努力增长技术，培养职业人脉，为2019年跳槽谷歌准备。 减脂增肌，可以发表ins, 粉丝数过千。 开始理财投资，合理处理收入。 习惯根据之前写的一日规划更改得到的： 12345678910111213141516171819202122232425262728一日作息6:50起床，喝水，厕所，温水洗漱7：20出门，早餐：鸡蛋，粥7:20-8:00 通勤，背单词，听pod8:00 工作：查收工作邮件，结合前一晚工作安排，安排今日工作上午安排最艰难工作10：30 放松眼睛，加餐，水果，牛奶或燕麦，二十分钟12:00 午餐：蘸水，细嚼慢咽，八分饱12:30-2:00 学一集mooc2:00-4:30 工作4：30 休息放松，加餐4:30-5:30 工作5:30-7:00 运动7:00 晚饭，蘸水，细嚼慢咽，八分饱7：30-8:30 工作8:30-9:30 制定第二天计划，记录到evernote，发周报，读书9:30-10:00 通勤，背单词，听pod10:00-11:00 洗漱，准备第二天衣物。补充上床不带手机不吃油炸，不喝任何饮料包括300kj以上的酸奶。rescuetime 监控时间。每天写下工作计划，每周写1-2篇博客适当增加加班时间。拒绝碎片化时间拒绝武林外传拒绝排球拒绝网球 1234567891011121314151617预算税后收入：+11651.38公积金：+1500租房：-2500生活开销：-2000每月存下8000货基：2000基金定投：2000p2p：2000债券：2000有利网： 无忧宝，定存宝支付宝：基金微信：基金各种投资收益每月更新一次","tags":[{"name":"杂谈","slug":"杂谈","permalink":"http://yoursite.com/tags/杂谈/"}]},{"title":"dbscan","date":"2016-09-27T01:34:26.000Z","path":"2016/09/27/dbscan/","text":"12345678910111213141516171819202122232425262728293031323334353637383940DBSCAN(D, eps, Minpts) C=0 for each unvisited point P in dataset D mark P as visited N=getNeighbors(P, eps) if sizeOf(N) &lt; Mints mark P as NOISE else C=next cluster expandCluster(P, N, C, eps, Minpts)expandCluster(P, N, C, eps, Minpts) add P to cluster C for each point P’ in N if P’ is not visited mark P’ as visited N’=getNeighbors(P’, eps) if sizeOf(N’) &gt;= minPts N = N joined with N’ if P’ is not yew cluster any cluster add P’ to cluster C","tags":[{"name":"machine learning","slug":"machine-learning","permalink":"http://yoursite.com/tags/machine-learning/"}]},{"title":"RDD编程","date":"2016-04-14T02:35:42.000Z","path":"2016/04/14/RDD编程/","text":"RDD基础弹性分布式数据集，操作方式：transform (one add to another) and action(调用add进行求值).当对rdd进行多次action操作时，使用rdd.cache()提高效率 两种创建rdd方式：来自外部数据集和来自对象集合 12lines=sc.textFile('README.md')lines=sc.parallelize(['good','bad']) 常见转换和行动操作针对各个元素的转化操作map,flatMap(传入函数返回可迭代对象)，filter(返回bool类型) 伪集合操作rdd.distinct():开销大，需要对所有数据通过网络进行混洗（shuffle） rdd.union():会有重 rdd.interseciont(anoter):去重，单个rdd重复也去，也要shuffle,性能差 rdd.subtract(anoter):shuffle rdd.sample(flalse,0,5,777): 采样，例子为50%，不放回 rdd.takeSample(true,100,777) 行动操作rdd.reduce(lambda x,y :x+y):接受一个函数作为参数，这个函数要操作两个rdd的元素的数据并且返回一个同样类型的新元素，多用于计算rdd中所有元素的总和，元素的个数等。 rdd.collect():要求能放进一台机器的内存中，因此多用于单元测试 rdd.take(100): 尝试访问尽量少的分区，操作会得到一个不均衡集合，返回顺序不定 rdd.top(100) 返回前100，可指定排序 rdd.takeOrdered(100)(myordering) rdd.foreach(func) 对rdd的每个元素使用func,例如 rdd.foreach(println) pair rddfor each pair rddrdd.reduceByKey(func): combine rdds with the same key,e.g. rdd.reduceByKey(lambda (x,y):x+y) rdd.groupByKey : e.g. rdd={(1,2),(3,4),(3,6)} ==&gt; {(1,[2]),(3,[4,6])} rdd.mapValues(func): imply func on each value with the key unchanged rdd.flatMapValues(func) rdd.keys(): return a new rdd consist of keys rdd.values() rdd.sortByKey() e.g. rdd.sortByKey(asending=true,numPartitions=None,keyFunc=labmda x:str(x)) for two pair rddrdd.subtractByKey(anoter) rdd.join(anoter): inner rdd.leftOuterJoin(anoter) rdd.rightOuterJoin(anoter) rdd.cogroup(anoter): e.g. rdd={(1,2),(3,4),(3,5)} anoter={(3,6)} ==&gt; {(1,([2],[])),(3,([4,5],[6])} combine actioncombineByKey()????? pair rdd actioncountByKey collectAsMap() lookup(key) 累加器累加器相当于全局变量 123file=sc.textFile('input.txt')#创建累机器并初始化为0blankLines=sc.accumulator(0) ​ 12345678def extractCallSigns(line): global blankLines #访问全局变量 if(lines==\"\"): blankLines+=1 return line.split(\"\\t\")callSigns=file.flatMap(extractCallSigns)callSigns.saveAsTextFile(outputDir+\"/callsigns\")print \"blank lins: %d\"%blankLines.values dataframegenerate df from sparkhive,each row is a object of ‘Row’,can convert tor rdd by ‘.rdd’ and you can get the item from the row by the index as well as the column name. e.g. x.pid ,x[0] 性能提升 rdd.textFile(‘sss’).repartition(10000）单个机器内存不够时，重新增加分区 rdd.coalesce(100).saveAsTextFile","tags":[{"name":"Spark","slug":"Spark","permalink":"http://yoursite.com/tags/Spark/"}]},{"title":"spark在hive中的应用","date":"2016-03-18T13:30:26.000Z","path":"2016/03/18/spark在hive中的应用/","text":"连接spark sqlsparksql提供一种特殊的rdd，叫做schemerdd,schemerdd是存放row对象的rdd，每个row对象代表一行记录。附带包含每列的类型信息。Row类型只是对基本数据类型的数组的封装。schemerdd开起来和普通的rdd很像，但是可以利用结构信息更加高效的存储数据。scheme可以从外部数据创建，也可以从查询结果或者普通rdd中创建。 SchemeRDD可以使用已有的rdd转化操作，比如map()和filter().furterhmore可以把任意的schemerdd注册为临时表（HiveContext.registerTempTable） Row对象表示schemerdd中的记录，其本质就是一个定长的字段数组，可以使用对应的getType()方法，比如getString(0)会把字段0按照字符串返回。 //访问toptweet这个schemerdd中的text列（第一列） val toptweet=toptweets.map(row=&gt;row.getString(0)) 若要把spark sql连接到一个部署好的hive上，必须把hive-site.xml复制到spark的配置文件目录中($spark_home/conf)。即使没有部署好hive,sparksql会在当前工作目录中创建出hive元数据库，叫作master_db。 在应用中使用spark sqlimportimport org.apache.spark.sql.hive.HiveContext import org.apache.spark.sql.SQLContext 隐式转换支持//创建spark sql的HiveContext val hiveCtx=... //导入隐式转换支持 import hiveCtx._ //创建上下文环境 val sc=new SparkContext(...) val hiveCtx=new HiveContext(sc)","tags":[{"name":"spark","slug":"spark","permalink":"http://yoursite.com/tags/spark/"}]},{"title":"spark初级","date":"2016-03-16T07:09:56.000Z","path":"2016/03/16/spark初级/","text":"预备从国内某约车软件实际工作出发，学习spark，特别感谢倚天同学指导。工作分了两部分，一部分是从hive表提取数据，第二部分是对本地数据进行统计。从hive提取数据需要hivesql相关知识，所以我先从第二份开始。 spark 本地数据统计//指明包的位置，类似于java package com.user import java.util import org.apache.spark.rdd.RDD import org.apache.spark.spark{SparkConf,SparkContext} /** * *created by yitian on 16/3/10 */ object Stat{ def main(args: Array[String]){ //首先要声明 sparkconf 和sparkcontext val sparkConf=new SparkConf().setAppName(this.getClass.getName+&quot;#jitian&quot;) val sc=new SparkContext(sparkConf) val filePath=&quot;/user/data&quot; val outPath=&quot;user/output&quot; val period=28.0 //统计阶段1 val statData=sc.textFile(filePath).map{ case str=&gt; val content=str.split(&quot;\\t&quot;) val pid=content(0) val phone=content(1) val pcost=content(3).toDouble val acost=content(4).toDouble ((pid,phone),(1,acost/pcost)) }.reduceByKey((a,b)=&gt;(a._1+b._1,a._2+b._2)) .map{case((pid,phone),(ocount,disSum))=&gt; ((pid,phone),(ocount/peroid,0.0,disSum,ocount)) } //其他阶段统计 } } 使用spark从hive表提取数据//部分 val sqlContext=new HiveContext(sc) val sqlText=&quot; &quot; //sql val dataExtracted=sqlContext.sql(sqlText).map{ case Row(pID: Long,pPhone: String,oId: Long,sCost:Double,aCost: Double)=&gt;pId.toString+&quot;\\t&quot;+pPhone+&quot;\\t&quot; }.repartition(5).saveAsTextFile(FILE_LOCATION)","tags":[{"name":"spark","slug":"spark","permalink":"http://yoursite.com/tags/spark/"}]},{"title":"hive总结","date":"2016-03-16T03:30:43.000Z","path":"2016/03/16/hive总结/","text":"创建(外)表的典型操作CREATE EXTERNAL TABEL &apos;passenger&apos;( &apos;city_id&apos; INT COMMENT &apos;城市id&apos;, ‘phone_number’ BIGINT COMMENT &apos;用户手机号&apos; ) COMMENT &apos;用户表&apos; PARTITION BY( &apos;year&apos; string, &apos;month&apos; string, &apos;day&apos; string ) row format delimited field terminated by &quot;\\t&quot; location &apos;hdfs: //---&apos; /*增加partition*/ ALTER TABLE passenger ADD IF NOT EXISTS PARTITION(year=&apos;2016&apos;,month=&apos;03&apos;,day=&apos;11&apos;) location=&apos;2016/03/11&apos; 查询结果的存储存储到hive表//创建表 insert overwrite table *** //查询语句 select * ... 存储到hdfs某一个目录insert overwrite directory &apos;hdfs_dir/...&apos; select *... 存储到本地目录insert overwirte local directory &apos;local_dir/...&apos; select * ... 向hive表装载数据//建表 LOAD DATA (LOCAL) INPATH &apos;/dir/...&apos; OVERWRITE INTO TABLE tablename PARTITION(dt=&apos; &apos;,country=&apos; &apos;); //设置字段条件 其他命令describe table; drop table ;show tables;!ls;","tags":[{"name":"hive","slug":"hive","permalink":"http://yoursite.com/tags/hive/"}]},{"title":"2016读书总结","date":"2016-01-05T13:57:39.000Z","path":"2016/01/05/2016读书总结/","text":"2015年部分读书清单岛上书店、时间守护着、浪潮之巅、黑客与画家、稀缺、富家美国 2016年读书总结","tags":[{"name":"阅读","slug":"阅读","permalink":"http://yoursite.com/tags/阅读/"}]},{"title":"2016版一日规划","date":"2016-01-05T03:39:21.000Z","path":"2016/01/05/2016版一日规划/","text":"一日作息 6:50起床 喝水，厕所，温水洗漱，7：20出门 早餐：鸡蛋，粥 工作： 查收工作邮件，结合前一晚工作安排，安排今日工作 上午安排最艰难工作 10：30 放松眼睛，加餐，水果，牛奶或燕麦，二十分钟 12:00 午餐：一荤一素，细嚼慢咽，八分饱 12:30-1:00 微博qq社交 1：00-1：30 午睡 1:30-2:00 阅读杂志 工作： to do 4点半加餐，哑铃小运动 to do 6:00 晚餐：一荤一素，细嚼慢咽，八分饱 6：30-7：00 阅读，查收邮件 7：00-10:00 工作，阅读，运动，录音 10:00-10:20 一天总结，第二天计划 10:20:撤,最后一次补水。洗漱，准备第二天衣服 11:00 睡！美梦 补充 工作期间qq不回，微信可以 上床不带手机 不吃油炸，不喝饮料，少吃高淀粉 碎片化的时间，不如路上可以背单词，听英文，听剧。 to be conti","tags":[{"name":"杂谈","slug":"杂谈","permalink":"http://yoursite.com/tags/杂谈/"}]},{"title":"Line Segment Intersection","date":"2015-12-30T07:30:39.000Z","path":"2015/12/30/Intersection/","text":"ProblemInput: A set $S=\\lbrace S_1,S_2,...,S_n\\rbrace $ of(closed)line segment in $R^2$ Output: All intersection points between segements in S In particular,we assume: The x-coordinates of the endpoints and intersection points are all distinct.(This implies that no line segment is vertical). If two segments intersect, then they intersect in a single point(they are not collinear). No three lines intersect in a common point. Plane Sweep Alg.Concepts Cleanliness property: all intersections to the left of sweep line $l$ have been reported Sweep line status: store segments that intersect the sweep line $l$ ,ordered along the intersection with $l$. Events: (1)Points in time when sweep line status chaneges combinatorially(i.e., the order of segments intersecting $l$ changes). (2)Endpoints of segments(insert in beginning) (3)Intersection points(computing on the fly during plane sweep) Intersection Lemma＊Lemma＊: Let $s$,$s’$ be two non-vertical segments whose interiors intersect in a single point $p$. Assume there is no third segment passing through $p$. Then there is an event point to the left of $p$ where $s$ and $s$,$s’$ become adjacent(and hence are tested for intersection). Data structure sweep line: orderded dictionary(balanced binary search tree) sorted vertically from top to down future event points: priority queue ordered from left to right by x-coordinates Alg Insert all of the points o the line segments of $S$ into the event queue. The initial sweep-line status is empty. while the event queue is nonempty, extract the next event in the queue.There are there cases,depending on the type of the event: Left endpoints: (a)insert this line segments $s$ into the sweep-line status,based on the y-coordinats of its left endpoints (b)Let $S$ and $s’$ be the segments immediately above and below $s$ on the sweep line. If there is an event associated with the pair, remove it from the event queue. (c)Test for intersection between $s$ and $s’$ and between $s$ and $s’’$ to the right of the sweep line. If so, add the correspoing event(s) to the event queue. Right endpoint: (a)Let $s$ and $s’$ be the segments immediately above and below the sweep line. (b)Delete segments $s$ from the sweep line status. (c)Test for intersections between $s$ and $s’$ to the right of the sweep line. If so, add the corresponding event to the event queue. Intersecion: (a) report this intersection. (b) Let $s$ and $s’$ be the two intersecting segments. Swap these two line segments in the sweep-line status. (c) As a result,$s$ and $s’$ have changed which segments are immediately above and below them. Remove any old events due to adjacencies that have ended and insert any new intersection events form adjacencies that have been created.","tags":[{"name":"Computational Geometry","slug":"Computational-Geometry","permalink":"http://yoursite.com/tags/Computational-Geometry/"}]},{"title":"极简主义","date":"2015-12-24T14:51:21.000Z","path":"2015/12/24/极简主义/","text":"极简主义 没有多余的摆设，将生活用品精简到最少，伊娃说：“这种极度削尖的方式，使人更容易将注意力集中房间里那些为数不多的物件上。这种环境令人心绪平静，也使人感官更敏锐。”这是极简主义者的基本信仰。同样信奉极简主义的还有我们伟大的乔布斯先生。据说，乔布斯生前拥有的物品非常少，除了一年四季穿的黑色上衣，就只有一套昂贵的印象设备。乔布斯同样也是个禅宗信徒，物品的削减，从一个侧面反映了他心灵的干净。 对物品的看法 不持有：超出自己管理能力的、不种爱的、无法回收利用或转送他人的、不适合自己，与自己生活方式不相符的物品。 珍惜我拥有的每一样东西，细致对待，珍惜他们就像刚开始拥有时那样。 尽力做到购买自己能力范围内的最好的物品。 对于物品的丢失和损坏保持一颗平常心，不过分懊悔和难过。","tags":[{"name":"极简主义","slug":"极简主义","permalink":"http://yoursite.com/tags/极简主义/"}]},{"title":"岁末年初","date":"2015-12-24T07:17:23.000Z","path":"2015/12/24/岁末年初/","text":"哈哈，我来啦。从小就比较懒，虽然学习成绩一直还算不错吧，可是就是很讨厌阅读和写作（可能潜意识里觉得对考试成绩没啥帮助），知道最近在大叔的熏陶下，我喜欢上了阅读，古典名著，悬疑小说，dm小说也开始看啦。最近又萌发了写东西的冲动，以前其实也是有随手记些笔记的习惯，但杂七杂八写的不多，更重要的是没能写出来和大家共享讨论，这当然就会导致思想的狭隘。所以以后尽可能和大家共享出来，互相讨论学习。 良师益友回顾这一年啊，首先是要感恩身边帮助我成长的亲人和朋友，首先是要感谢老爹和老妈啦，父母年龄大了，生活中还有许多不顺利，希望老头老太太今后生活能够一帆风顺。不过我还是对二老有点意见的，就是俩人都不够坚强啊，喜欢抱怨和逃避现实，哎，也可能是我不够理解他们吧。接下来我要感谢峰峰童鞋，没记错的话，跟峰峰认识是15年1月16日，看了电影《重返20岁》，当时电影院还掉金豆子啦，哈哈，第一次好丢人啊。峰峰同学还是很优秀滴，本攻比较满意哈，爱妃就继续加油吧。三次元最重要的朋友就是洛阳市小商品君啦，小商品君是练现代五项的，一个女的比我还高，炒鸡厉害，重点是智商情商双高，真是出乎我意料（这话不定期删，啊哈哈），小商品君对我还是很毒舌的，今天还问我会不会得病，真是够了，不过我知道其实心里还是关心着我呢。么么哒，今后继续相爱相杀啊，最重要的是找我配攻啊，我是小小江呀。 羽毛球今年下半年开始，跟学姐一起开始打球，并且逐渐爱上啦，虽然打得还不咋滴啊。主要是自己基础力量比较差，不过会努力的，不能辜负大叔给买的1000+的球拍呢。还有通过打球结交球友的目标没有实现呢，希望16年球场上更加自信开朗，虚心学习，交上更多更好的朋友。 配音配音这事今年好想也是荒废了，没啥进展，之前因为学业的事失踪了一段时间，今后希望这种事不会再发生了吧，网配这事不是立即就能见效果的，这个月录的音很有可能很有之后才能发，所以就一直坚持的做下去吧。当然最重要的是做好自己，磨练声音，体会角色，提升戏感。所说两句，配音时 未完待续","tags":[{"name":"杂谈","slug":"杂谈","permalink":"http://yoursite.com/tags/杂谈/"}]},{"title":"Hello World","date":"2015-12-24T06:36:22.000Z","path":"2015/12/24/hello-world/","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" The Arithmetic mean is equal is $\\frac{1}{n} \\sum_{i=i}^{n} x_{i}$, or the sumation of n numbers divided by n. More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","tags":[]}]